{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a demo on how to use the DataLoader to upload kgtk(\\*.tsv) and annotated spreadsheets (\\*.csv or \\*.xlsx) to Datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Support\n",
    "---\n",
    "`DataLoader` currently supports the following functionalities:\n",
    "1. `template` ++ `[spreadsheet]+` => `annotated_spreadsheet` => `Datamart` => `None`\n",
    "2. `annotated_spreadsheet` ++ `[yaml_file]?` => `Datamart` => **UNION**[`t2wml_output`, `exploded_kgtk`, `None`]\n",
    "3. `exploded_kgtk` => `Datamart` => `None`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Users will be able to inject their parameters through commandline. Currently the following parameters are supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters to be injected\n",
    "\n",
    "datamart_api_url = 'http://localhost:12543'\n",
    "# [optional]\n",
    "dataset_id = None\n",
    "put_data = False\n",
    "DEBUG = False\n",
    "username = None\n",
    "password = None\n",
    "TEST_ALL = False\n",
    "\n",
    "\n",
    "# [params] combining template and data\n",
    "template_path = None\n",
    "dataset_path = None\n",
    "# [optional params]\n",
    "flag_combine_files = False\n",
    "save_template_path = None\n",
    "save_tsv_path = None\n",
    "save_t2wml_path = None\n",
    "Verbose = False\n",
    "\n",
    "\n",
    "# [params] submitting one annotated spreadsheet\n",
    "annotated_path = None\n",
    "annotated_dir_path = None\n",
    "# [optional params]\n",
    "yamlfile_path = None\n",
    "wikifier_path = None\n",
    "extra_edges_path = None\n",
    "validate = True\n",
    "\n",
    "# [params] submitting kgtk file\n",
    "tsv_path = None\n",
    "tsv_tar_path = None\n",
    "\n",
    "\n",
    "# [params] erase one dataset\n",
    "dataset_id_to_erase = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prase authentication\n",
    "if username and password:\n",
    "    auth = (username, password)\n",
    "else:\n",
    "    auth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python modules and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import spreadsheet, utility, upload, erase, template, get_, plot_\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a dataset if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_id_to_erase:\n",
    "    erase.erase_dataset(datamart_api_url, dataset_id_to_erase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the annotated sheet, and add it to Datamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfiles, nsheets = 0, 0\n",
    "if template_path and dataset_path:\n",
    "    if dataset_id is None:\n",
    "        dataset_id = utility.read_tsv(template_path).iat[0,1]\n",
    "\n",
    "    nfiles, nsheets = upload.submit_sheet_bulk(datamart_api_url, template_path, \n",
    "                                               dataset_path, flag_combine_files, put_data, auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If needed, save the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not save_template_path is None:\n",
    "    template.save_annotation_template(utility.read_tsv(template_path), save_template_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the annotated sheet, and add it to Datamart\n",
    "\n",
    "Returned files will be saved at save_tsv or save_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if annotated_path:\n",
    "    if upload.submit_annotated_sheet(datamart_api_url, annotated_path, yamlfile_path, put_data=put_data,\n",
    "                                        verbose=Verbose, save_tsv=save_tsv_path, save_files=save_t2wml_path,\n",
    "                                        auth=auth, validate=validate, wikifier_file=wikifier_path,\n",
    "                                        extra_edges_file=extra_edges_path):\n",
    "        nsheets += 1\n",
    "        nfiles += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if annotated_dir_path:\n",
    "    success, ct = upload.submit_annotated_dir(datamart_api_url, annotated_dir_path, yamlfile_path, put_data=put_data,\n",
    "                                                verbose=Verbose, save_tsv=save_tsv_path, save_files=save_t2wml_path,\n",
    "                                                auth=auth, validate=validate, wikifier_file=wikifier_path,\n",
    "                                                extra_edges_file=extra_edges_path)\n",
    "    nsheets += ct\n",
    "    nfiles += ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tsv file, and add it to Datamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tsv_path:\n",
    "    if upload.submit_tsv(datamart_api_url, tsv_path, put_data=put_data, auth=auth):\n",
    "        nfiles += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tsv_tar_path:\n",
    "    if upload.submit_tar(datamart_api_url, tsv_tar_path, dataset_id, put_data=put_data, \n",
    "                         verbose=Verbose, auth=auth):\n",
    "        nfiles += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate statistics for bug checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{nfiles} files processed.')\n",
    "print(f'{nsheets} sheets uploaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the state after uploading datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = get_.metadata(datamart_api_url, auth=auth)\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### variable metadata, data, trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG and dataset_id is not None:\n",
    "    var_metadata = get_.variable_metadata(datamart_api_url, dataset_id, auth=auth)\n",
    "    display(var_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    try:\n",
    "        for variable_id in var_metadata['variable_id']:\n",
    "            try:\n",
    "                data = get_.variable_data(datamart_api_url, dataset_id, variable_id, auth=auth)\n",
    "                display(data)\n",
    "\n",
    "                plot_.trend_df(data, variable_id)\n",
    "\n",
    "                if not TEST_ALL:\n",
    "                    break\n",
    "            except Exception as ex:\n",
    "                print('Error:', ex)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error:', e)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
